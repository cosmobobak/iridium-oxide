{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome</th>\n",
       "      <th>moves</th>\n",
       "      <th>board</th>\n",
       "      <th>-</th>\n",
       "      <th>-.1</th>\n",
       "      <th>-.2</th>\n",
       "      <th>-.3</th>\n",
       "      <th>-.4</th>\n",
       "      <th>-.5</th>\n",
       "      <th>-.6</th>\n",
       "      <th>...</th>\n",
       "      <th>-.80</th>\n",
       "      <th>-.81</th>\n",
       "      <th>-.82</th>\n",
       "      <th>policy</th>\n",
       "      <th>-.83</th>\n",
       "      <th>-.84</th>\n",
       "      <th>-.85</th>\n",
       "      <th>-.86</th>\n",
       "      <th>-.87</th>\n",
       "      <th>-.88</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   outcome  moves  board  -  -.1  -.2  -.3  -.4  -.5  -.6  ...  -.80  -.81  \\\n",
       "0        1      0      0  0    0    0    0    0    0    0  ...     0     0   \n",
       "1        1      1      0  0    0    0    0    0    0    0  ...     0     0   \n",
       "2        1      1      0  0    0    0    0    0    0    0  ...     1     0   \n",
       "3        1      2      0  0    0    0    0    0    0    0  ...     1     1   \n",
       "4        1      2      0  0    0    0    0    0    0    0  ...     0     0   \n",
       "\n",
       "   -.82  policy   -.83   -.84   -.85   -.86   -.87   -.88  \n",
       "0     0   0.024  0.038  0.058  0.758  0.057  0.038  0.025  \n",
       "1     1   0.039  0.054  0.068  0.636  0.105  0.059  0.039  \n",
       "2     0   0.038  0.044  0.114  0.506  0.193  0.063  0.042  \n",
       "3     0   0.038  0.054  0.214  0.529  0.043  0.081  0.041  \n",
       "4     1   0.045  0.050  0.346  0.361  0.051  0.082  0.065  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../datasets/connect4data.csv', index_col=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTRIES = data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = np.array(data[[\"board\", \"-\"] + [f\"-.{i}\" for i in range(1, 83)]])\n",
    "policies = np.array(data[[\"policy\"] + [f\"-.{i}\" for i in range(83, 89)]])\n",
    "states[0]\n",
    "firstpolicy = policies[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = states.reshape(ENTRIES, 6, 7, 2)  # reshape to 6x7x2 for cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(zip(states, policies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "np.random.shuffle(data)\n",
    "# split into train and test\n",
    "train_data = data[:int(ENTRIES*0.8)]\n",
    "test_data = data[int(ENTRIES*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 6, 7, 2)]    0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 6, 7, 128)    2432        ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 6, 7, 128)    147584      ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 6, 7, 128)    147584      ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 128)         0           ['conv2d_2[0][0]']               \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1, 128)    0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 1, 8)      1024        ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 1, 128)    1024        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 6, 7, 128)    0           ['conv2d_2[0][0]',               \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 6, 7, 128)    0           ['multiply[0][0]',               \n",
      "                                                                  'conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 6, 7, 128)    147584      ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 6, 7, 128)    147584      ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 128)         0           ['conv2d_4[0][0]']               \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 1, 1, 128)    0           ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1, 1, 8)      1024        ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1, 1, 128)    1024        ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 6, 7, 128)    0           ['conv2d_4[0][0]',               \n",
      "                                                                  'dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 6, 7, 128)    0           ['multiply_1[0][0]',             \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 6, 7, 128)    147584      ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 6, 7, 128)    147584      ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 128)         0           ['conv2d_6[0][0]']               \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 1, 1, 128)    0           ['global_average_pooling2d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 1, 1, 8)      1024        ['reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1, 1, 128)    1024        ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)          (None, 6, 7, 128)    0           ['conv2d_6[0][0]',               \n",
      "                                                                  'dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 6, 7, 128)    0           ['multiply_2[0][0]',             \n",
      "                                                                  'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 6, 7, 128)    147584      ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 6, 7, 128)    147584      ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling2d_3 (Gl  (None, 128)         0           ['conv2d_8[0][0]']               \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 1, 1, 128)    0           ['global_average_pooling2d_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 1, 1, 8)      1024        ['reshape_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1, 1, 128)    1024        ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " multiply_3 (Multiply)          (None, 6, 7, 128)    0           ['conv2d_8[0][0]',               \n",
      "                                                                  'dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 6, 7, 128)    0           ['multiply_3[0][0]',             \n",
      "                                                                  'add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 6, 7, 128)    147584      ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 6, 7, 128)    147584      ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling2d_4 (Gl  (None, 128)         0           ['conv2d_10[0][0]']              \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_4 (Reshape)            (None, 1, 1, 128)    0           ['global_average_pooling2d_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 1, 1, 8)      1024        ['reshape_4[0][0]']              \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1, 1, 128)    1024        ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " multiply_4 (Multiply)          (None, 6, 7, 128)    0           ['conv2d_10[0][0]',              \n",
      "                                                                  'dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 6, 7, 128)    0           ['multiply_4[0][0]',             \n",
      "                                                                  'add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 6, 7, 128)    147584      ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 6, 7, 128)    147584      ['conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling2d_5 (Gl  (None, 128)         0           ['conv2d_12[0][0]']              \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_5 (Reshape)            (None, 1, 1, 128)    0           ['global_average_pooling2d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 1, 1, 8)      1024        ['reshape_5[0][0]']              \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 1, 1, 128)    1024        ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_5 (Multiply)          (None, 6, 7, 128)    0           ['conv2d_12[0][0]',              \n",
      "                                                                  'dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 6, 7, 128)    0           ['multiply_5[0][0]',             \n",
      "                                                                  'add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 6, 7, 128)    147584      ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 6, 7, 128)    147584      ['conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling2d_6 (Gl  (None, 128)         0           ['conv2d_14[0][0]']              \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_6 (Reshape)            (None, 1, 1, 128)    0           ['global_average_pooling2d_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 1, 1, 8)      1024        ['reshape_6[0][0]']              \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 1, 1, 128)    1024        ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_6 (Multiply)          (None, 6, 7, 128)    0           ['conv2d_14[0][0]',              \n",
      "                                                                  'dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 6, 7, 128)    0           ['multiply_6[0][0]',             \n",
      "                                                                  'add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 6, 7, 128)    147584      ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 6, 7, 128)    147584      ['conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling2d_7 (Gl  (None, 128)         0           ['conv2d_16[0][0]']              \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_7 (Reshape)            (None, 1, 1, 128)    0           ['global_average_pooling2d_7[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 1, 1, 8)      1024        ['reshape_7[0][0]']              \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 1, 1, 128)    1024        ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_7 (Multiply)          (None, 6, 7, 128)    0           ['conv2d_16[0][0]',              \n",
      "                                                                  'dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 6, 7, 128)    0           ['multiply_7[0][0]',             \n",
      "                                                                  'add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 6, 7, 128)    147584      ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 6, 7, 128)    147584      ['conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling2d_8 (Gl  (None, 128)         0           ['conv2d_18[0][0]']              \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_8 (Reshape)            (None, 1, 1, 128)    0           ['global_average_pooling2d_8[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 1, 1, 8)      1024        ['reshape_8[0][0]']              \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 1, 1, 128)    1024        ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_8 (Multiply)          (None, 6, 7, 128)    0           ['conv2d_18[0][0]',              \n",
      "                                                                  'dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 6, 7, 128)    0           ['multiply_8[0][0]',             \n",
      "                                                                  'add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 6, 7, 128)    147584      ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 6, 7, 128)    147584      ['conv2d_19[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling2d_9 (Gl  (None, 128)         0           ['conv2d_20[0][0]']              \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_9 (Reshape)            (None, 1, 1, 128)    0           ['global_average_pooling2d_9[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 1, 1, 8)      1024        ['reshape_9[0][0]']              \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 1, 1, 128)    1024        ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_9 (Multiply)          (None, 6, 7, 128)    0           ['conv2d_20[0][0]',              \n",
      "                                                                  'dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 6, 7, 128)    0           ['multiply_9[0][0]',             \n",
      "                                                                  'add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 6, 7, 32)     4128        ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1344)         0           ['conv2d_21[0][0]']              \n",
      "                                                                                                  \n",
      " policy_head (Dense)            (None, 7)            9415        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,988,135\n",
      "Trainable params: 2,988,135\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from net import get_model\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "xs = np.array([x for x, _ in train_data])\n",
    "ys = np.array([y for _, y in train_data])\n",
    "xs_test = np.array([x for x, _ in test_data])\n",
    "ys_test = np.array([y for _, y in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard\n",
    "import datetime\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir, histogram_freq=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "397/397 [==============================] - 36s 90ms/step - loss: 1.8696 - accuracy: 0.2845 - val_loss: 1.9031 - val_accuracy: 0.2534\n",
      "Epoch 2/500\n",
      "397/397 [==============================] - 27s 67ms/step - loss: 1.8517 - accuracy: 0.3110 - val_loss: 1.9124 - val_accuracy: 0.2124\n",
      "Epoch 3/500\n",
      "397/397 [==============================] - 24s 60ms/step - loss: 1.8317 - accuracy: 0.3288 - val_loss: 1.9671 - val_accuracy: 0.2237\n",
      "Epoch 4/500\n",
      "397/397 [==============================] - 26s 66ms/step - loss: 1.8137 - accuracy: 0.3478 - val_loss: 1.8677 - val_accuracy: 0.2717\n",
      "Epoch 5/500\n",
      "397/397 [==============================] - 26s 66ms/step - loss: 1.7992 - accuracy: 0.3585 - val_loss: 1.8025 - val_accuracy: 0.3711\n",
      "Epoch 6/500\n",
      "397/397 [==============================] - 24s 61ms/step - loss: 1.7875 - accuracy: 0.3719 - val_loss: 1.7803 - val_accuracy: 0.3821\n",
      "Epoch 7/500\n",
      "397/397 [==============================] - 28s 70ms/step - loss: 1.7743 - accuracy: 0.3863 - val_loss: 1.7748 - val_accuracy: 0.3799\n",
      "Epoch 8/500\n",
      "397/397 [==============================] - 27s 69ms/step - loss: 1.7606 - accuracy: 0.3897 - val_loss: 1.8026 - val_accuracy: 0.3588\n",
      "Epoch 9/500\n",
      "397/397 [==============================] - 31s 77ms/step - loss: 1.7439 - accuracy: 0.3992 - val_loss: 1.8656 - val_accuracy: 0.3708\n",
      "Epoch 10/500\n",
      "397/397 [==============================] - 24s 62ms/step - loss: 1.7265 - accuracy: 0.4124 - val_loss: 1.7788 - val_accuracy: 0.3534\n",
      "Epoch 11/500\n",
      "397/397 [==============================] - 27s 68ms/step - loss: 1.7106 - accuracy: 0.4273 - val_loss: 1.7801 - val_accuracy: 0.3452\n",
      "Epoch 12/500\n",
      "397/397 [==============================] - 27s 67ms/step - loss: 1.6950 - accuracy: 0.4343 - val_loss: 1.7030 - val_accuracy: 0.4263\n",
      "Epoch 13/500\n",
      "397/397 [==============================] - 23s 59ms/step - loss: 1.6801 - accuracy: 0.4418 - val_loss: 1.7229 - val_accuracy: 0.3970\n",
      "Epoch 14/500\n",
      "397/397 [==============================] - 26s 64ms/step - loss: 1.6670 - accuracy: 0.4557 - val_loss: 1.7542 - val_accuracy: 0.3714\n",
      "Epoch 15/500\n",
      "397/397 [==============================] - 25s 63ms/step - loss: 1.6536 - accuracy: 0.4669 - val_loss: 1.7161 - val_accuracy: 0.4033\n",
      "Epoch 16/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.6385 - accuracy: 0.4804 - val_loss: 1.7624 - val_accuracy: 0.4068\n",
      "Epoch 17/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.6250 - accuracy: 0.4895 - val_loss: 1.6689 - val_accuracy: 0.4471\n",
      "Epoch 18/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.6103 - accuracy: 0.4982 - val_loss: 1.8707 - val_accuracy: 0.3383\n",
      "Epoch 19/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.5995 - accuracy: 0.5118 - val_loss: 1.7769 - val_accuracy: 0.3894\n",
      "Epoch 20/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.5844 - accuracy: 0.5260 - val_loss: 1.7739 - val_accuracy: 0.3739\n",
      "Epoch 21/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.5706 - accuracy: 0.5310 - val_loss: 1.7670 - val_accuracy: 0.4004\n",
      "Epoch 22/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.5551 - accuracy: 0.5437 - val_loss: 1.7303 - val_accuracy: 0.4235\n",
      "Epoch 23/500\n",
      "397/397 [==============================] - 23s 59ms/step - loss: 1.5435 - accuracy: 0.5535 - val_loss: 1.8391 - val_accuracy: 0.4008\n",
      "Epoch 24/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.5324 - accuracy: 0.5594 - val_loss: 1.6745 - val_accuracy: 0.4323\n",
      "Epoch 25/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.5166 - accuracy: 0.5726 - val_loss: 2.0833 - val_accuracy: 0.3203\n",
      "Epoch 26/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.5072 - accuracy: 0.5726 - val_loss: 1.8708 - val_accuracy: 0.3869\n",
      "Epoch 27/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.4963 - accuracy: 0.5888 - val_loss: 2.0502 - val_accuracy: 0.3607\n",
      "Epoch 28/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.4836 - accuracy: 0.5961 - val_loss: 2.2043 - val_accuracy: 0.3250\n",
      "Epoch 29/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.4745 - accuracy: 0.6012 - val_loss: 2.0767 - val_accuracy: 0.3383\n",
      "Epoch 30/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.4655 - accuracy: 0.6090 - val_loss: 1.9170 - val_accuracy: 0.4203\n",
      "Epoch 31/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.4519 - accuracy: 0.6215 - val_loss: 3.0792 - val_accuracy: 0.2872\n",
      "Epoch 32/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.4637 - accuracy: 0.6105 - val_loss: 1.8602 - val_accuracy: 0.4042\n",
      "Epoch 33/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.4334 - accuracy: 0.6338 - val_loss: 1.7381 - val_accuracy: 0.4879\n",
      "Epoch 34/500\n",
      "397/397 [==============================] - 23s 59ms/step - loss: 1.4215 - accuracy: 0.6402 - val_loss: 2.1132 - val_accuracy: 0.3405\n",
      "Epoch 35/500\n",
      "397/397 [==============================] - 26s 65ms/step - loss: 1.4160 - accuracy: 0.6453 - val_loss: 1.6118 - val_accuracy: 0.4986\n",
      "Epoch 36/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.4047 - accuracy: 0.6558 - val_loss: 1.8351 - val_accuracy: 0.3979\n",
      "Epoch 37/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.3957 - accuracy: 0.6604 - val_loss: 1.6246 - val_accuracy: 0.4913\n",
      "Epoch 38/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.3865 - accuracy: 0.6641 - val_loss: 2.3664 - val_accuracy: 0.3619\n",
      "Epoch 39/500\n",
      "397/397 [==============================] - 24s 59ms/step - loss: 1.3824 - accuracy: 0.6699 - val_loss: 1.8046 - val_accuracy: 0.4531\n",
      "Epoch 40/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.3714 - accuracy: 0.6741 - val_loss: 2.2701 - val_accuracy: 0.3916\n",
      "Epoch 41/500\n",
      "397/397 [==============================] - 25s 63ms/step - loss: 1.3695 - accuracy: 0.6824 - val_loss: 1.8183 - val_accuracy: 0.4235\n",
      "Epoch 42/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.3572 - accuracy: 0.6889 - val_loss: 1.6745 - val_accuracy: 0.4967\n",
      "Epoch 43/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.3521 - accuracy: 0.6946 - val_loss: 1.7986 - val_accuracy: 0.3831\n",
      "Epoch 44/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.3527 - accuracy: 0.6908 - val_loss: 1.5967 - val_accuracy: 0.5374\n",
      "Epoch 45/500\n",
      "397/397 [==============================] - 27s 67ms/step - loss: 1.3343 - accuracy: 0.7003 - val_loss: 1.7862 - val_accuracy: 0.4866\n",
      "Epoch 46/500\n",
      "397/397 [==============================] - 23s 59ms/step - loss: 1.3327 - accuracy: 0.7053 - val_loss: 1.7352 - val_accuracy: 0.4973\n",
      "Epoch 47/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.3219 - accuracy: 0.7163 - val_loss: 1.7907 - val_accuracy: 0.4692\n",
      "Epoch 48/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.3167 - accuracy: 0.7202 - val_loss: 1.8271 - val_accuracy: 0.3970\n",
      "Epoch 49/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.3127 - accuracy: 0.7199 - val_loss: 1.5429 - val_accuracy: 0.5573\n",
      "Epoch 50/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.3031 - accuracy: 0.7238 - val_loss: 1.5571 - val_accuracy: 0.5516\n",
      "Epoch 51/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.2992 - accuracy: 0.7282 - val_loss: 3.5511 - val_accuracy: 0.2963\n",
      "Epoch 52/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.3112 - accuracy: 0.7291 - val_loss: 1.6519 - val_accuracy: 0.5017\n",
      "Epoch 53/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.2861 - accuracy: 0.7424 - val_loss: 3.9071 - val_accuracy: 0.1745\n",
      "Epoch 54/500\n",
      "397/397 [==============================] - 23s 59ms/step - loss: 1.3124 - accuracy: 0.7226 - val_loss: 1.5447 - val_accuracy: 0.5601\n",
      "Epoch 55/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.2768 - accuracy: 0.7511 - val_loss: 1.6800 - val_accuracy: 0.4920\n",
      "Epoch 56/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.2746 - accuracy: 0.7500 - val_loss: 2.0723 - val_accuracy: 0.4159\n",
      "Epoch 57/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.2718 - accuracy: 0.7516 - val_loss: 1.5925 - val_accuracy: 0.5194\n",
      "Epoch 58/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.2647 - accuracy: 0.7564 - val_loss: 1.7797 - val_accuracy: 0.4721\n",
      "Epoch 59/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.2613 - accuracy: 0.7599 - val_loss: 1.5595 - val_accuracy: 0.5595\n",
      "Epoch 60/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.2569 - accuracy: 0.7619 - val_loss: 1.5933 - val_accuracy: 0.5380\n",
      "Epoch 61/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.2501 - accuracy: 0.7660 - val_loss: 1.5179 - val_accuracy: 0.5702\n",
      "Epoch 62/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.2485 - accuracy: 0.7714 - val_loss: 1.6363 - val_accuracy: 0.5011\n",
      "Epoch 63/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.2440 - accuracy: 0.7690 - val_loss: 1.5296 - val_accuracy: 0.5866\n",
      "Epoch 64/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.2385 - accuracy: 0.7768 - val_loss: 1.8910 - val_accuracy: 0.4443\n",
      "Epoch 65/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.2407 - accuracy: 0.7771 - val_loss: 2.0940 - val_accuracy: 0.4288\n",
      "Epoch 66/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.2414 - accuracy: 0.7754 - val_loss: 1.5685 - val_accuracy: 0.5522\n",
      "Epoch 67/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.2307 - accuracy: 0.7841 - val_loss: 1.5576 - val_accuracy: 0.5494\n",
      "Epoch 68/500\n",
      "397/397 [==============================] - 23s 57ms/step - loss: 1.2262 - accuracy: 0.7895 - val_loss: 1.5194 - val_accuracy: 0.5898\n",
      "Epoch 69/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.2225 - accuracy: 0.7901 - val_loss: 1.5396 - val_accuracy: 0.5740\n",
      "Epoch 70/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.2194 - accuracy: 0.7931 - val_loss: 1.6389 - val_accuracy: 0.5273\n",
      "Epoch 71/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.2190 - accuracy: 0.7915 - val_loss: 1.5803 - val_accuracy: 0.5541\n",
      "Epoch 72/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.2137 - accuracy: 0.7956 - val_loss: 1.7757 - val_accuracy: 0.5121\n",
      "Epoch 73/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.2132 - accuracy: 0.8001 - val_loss: 1.5799 - val_accuracy: 0.5472\n",
      "Epoch 74/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.2101 - accuracy: 0.7971 - val_loss: 1.6050 - val_accuracy: 0.5611\n",
      "Epoch 75/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.2070 - accuracy: 0.8016 - val_loss: 2.5604 - val_accuracy: 0.4219\n",
      "Epoch 76/500\n",
      "397/397 [==============================] - 23s 59ms/step - loss: 1.2122 - accuracy: 0.7994 - val_loss: 1.5869 - val_accuracy: 0.5740\n",
      "Epoch 77/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.2014 - accuracy: 0.8094 - val_loss: 1.6962 - val_accuracy: 0.5077\n",
      "Epoch 78/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.1998 - accuracy: 0.8065 - val_loss: 1.8114 - val_accuracy: 0.5235\n",
      "Epoch 79/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.1969 - accuracy: 0.8102 - val_loss: 1.5830 - val_accuracy: 0.5551\n",
      "Epoch 80/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.1937 - accuracy: 0.8143 - val_loss: 1.6426 - val_accuracy: 0.5314\n",
      "Epoch 81/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.1929 - accuracy: 0.8132 - val_loss: 2.0272 - val_accuracy: 0.4598\n",
      "Epoch 82/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.1964 - accuracy: 0.8102 - val_loss: 1.5671 - val_accuracy: 0.5715\n",
      "Epoch 83/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.1866 - accuracy: 0.8196 - val_loss: 1.5433 - val_accuracy: 0.5680\n",
      "Epoch 84/500\n",
      "397/397 [==============================] - 23s 58ms/step - loss: 1.1843 - accuracy: 0.8252 - val_loss: 1.7072 - val_accuracy: 0.5014\n",
      "Epoch 85/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1864 - accuracy: 0.8188 - val_loss: 1.8023 - val_accuracy: 0.5330\n",
      "Epoch 86/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1839 - accuracy: 0.8194 - val_loss: 1.5733 - val_accuracy: 0.5364\n",
      "Epoch 87/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1801 - accuracy: 0.8230 - val_loss: 1.6758 - val_accuracy: 0.5415\n",
      "Epoch 88/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1781 - accuracy: 0.8276 - val_loss: 1.5981 - val_accuracy: 0.5803\n",
      "Epoch 89/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1764 - accuracy: 0.8293 - val_loss: 1.5680 - val_accuracy: 0.5611\n",
      "Epoch 90/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1753 - accuracy: 0.8285 - val_loss: 1.6130 - val_accuracy: 0.5595\n",
      "Epoch 91/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1725 - accuracy: 0.8313 - val_loss: 1.6118 - val_accuracy: 0.5443\n",
      "Epoch 92/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1746 - accuracy: 0.8312 - val_loss: 1.7537 - val_accuracy: 0.5131\n",
      "Epoch 93/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1762 - accuracy: 0.8286 - val_loss: 1.8541 - val_accuracy: 0.4591\n",
      "Epoch 94/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1700 - accuracy: 0.8382 - val_loss: 1.9677 - val_accuracy: 0.4200\n",
      "Epoch 95/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1749 - accuracy: 0.8315 - val_loss: 1.6039 - val_accuracy: 0.5620\n",
      "Epoch 96/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1684 - accuracy: 0.8374 - val_loss: 1.7160 - val_accuracy: 0.5289\n",
      "Epoch 97/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1652 - accuracy: 0.8375 - val_loss: 1.7403 - val_accuracy: 0.5273\n",
      "Epoch 98/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1651 - accuracy: 0.8403 - val_loss: 1.7566 - val_accuracy: 0.5039\n",
      "Epoch 99/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1629 - accuracy: 0.8427 - val_loss: 1.5464 - val_accuracy: 0.5895\n",
      "Epoch 100/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1613 - accuracy: 0.8442 - val_loss: 1.5803 - val_accuracy: 0.5822\n",
      "Epoch 101/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1612 - accuracy: 0.8442 - val_loss: 1.5524 - val_accuracy: 0.5813\n",
      "Epoch 102/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1587 - accuracy: 0.8463 - val_loss: 1.9402 - val_accuracy: 0.4579\n",
      "Epoch 103/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1635 - accuracy: 0.8440 - val_loss: 1.8079 - val_accuracy: 0.4512\n",
      "Epoch 104/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1702 - accuracy: 0.8357 - val_loss: 1.5748 - val_accuracy: 0.5677\n",
      "Epoch 105/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1551 - accuracy: 0.8465 - val_loss: 1.5889 - val_accuracy: 0.5740\n",
      "Epoch 106/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1527 - accuracy: 0.8485 - val_loss: 1.5827 - val_accuracy: 0.5879\n",
      "Epoch 107/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1537 - accuracy: 0.8503 - val_loss: 1.5473 - val_accuracy: 0.5939\n",
      "Epoch 108/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1506 - accuracy: 0.8536 - val_loss: 2.0211 - val_accuracy: 0.4677\n",
      "Epoch 109/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1622 - accuracy: 0.8428 - val_loss: 1.5628 - val_accuracy: 0.5778\n",
      "Epoch 110/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1506 - accuracy: 0.8528 - val_loss: 1.5921 - val_accuracy: 0.5809\n",
      "Epoch 111/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1485 - accuracy: 0.8588 - val_loss: 1.5953 - val_accuracy: 0.5857\n",
      "Epoch 112/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1467 - accuracy: 0.8597 - val_loss: 1.7254 - val_accuracy: 0.5163\n",
      "Epoch 113/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1508 - accuracy: 0.8539 - val_loss: 1.6778 - val_accuracy: 0.5175\n",
      "Epoch 114/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1460 - accuracy: 0.8572 - val_loss: 1.7442 - val_accuracy: 0.5200\n",
      "Epoch 115/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1467 - accuracy: 0.8575 - val_loss: 1.5480 - val_accuracy: 0.5914\n",
      "Epoch 116/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1422 - accuracy: 0.8651 - val_loss: 1.5771 - val_accuracy: 0.5753\n",
      "Epoch 117/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1433 - accuracy: 0.8616 - val_loss: 1.5998 - val_accuracy: 0.5544\n",
      "Epoch 118/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1435 - accuracy: 0.8636 - val_loss: 1.6594 - val_accuracy: 0.5210\n",
      "Epoch 119/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1466 - accuracy: 0.8562 - val_loss: 1.5450 - val_accuracy: 0.5876\n",
      "Epoch 120/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1409 - accuracy: 0.8616 - val_loss: 1.5718 - val_accuracy: 0.5850\n",
      "Epoch 121/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1402 - accuracy: 0.8659 - val_loss: 1.7005 - val_accuracy: 0.5191\n",
      "Epoch 122/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1400 - accuracy: 0.8661 - val_loss: 1.5894 - val_accuracy: 0.5623\n",
      "Epoch 123/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1387 - accuracy: 0.8667 - val_loss: 1.6167 - val_accuracy: 0.5686\n",
      "Epoch 124/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1377 - accuracy: 0.8670 - val_loss: 1.5664 - val_accuracy: 0.5917\n",
      "Epoch 125/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1374 - accuracy: 0.8715 - val_loss: 1.5676 - val_accuracy: 0.5790\n",
      "Epoch 126/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1359 - accuracy: 0.8715 - val_loss: 1.6248 - val_accuracy: 0.5598\n",
      "Epoch 127/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1370 - accuracy: 0.8660 - val_loss: 1.5865 - val_accuracy: 0.5699\n",
      "Epoch 128/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1353 - accuracy: 0.8723 - val_loss: 1.5487 - val_accuracy: 0.5863\n",
      "Epoch 129/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1340 - accuracy: 0.8744 - val_loss: 1.5516 - val_accuracy: 0.5879\n",
      "Epoch 130/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1334 - accuracy: 0.8764 - val_loss: 1.5921 - val_accuracy: 0.5661\n",
      "Epoch 131/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1336 - accuracy: 0.8757 - val_loss: 1.6318 - val_accuracy: 0.5405\n",
      "Epoch 132/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1326 - accuracy: 0.8719 - val_loss: 1.6917 - val_accuracy: 0.5592\n",
      "Epoch 133/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1347 - accuracy: 0.8742 - val_loss: 1.5994 - val_accuracy: 0.5607\n",
      "Epoch 134/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1331 - accuracy: 0.8750 - val_loss: 1.7510 - val_accuracy: 0.5222\n",
      "Epoch 135/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1365 - accuracy: 0.8739 - val_loss: 1.5752 - val_accuracy: 0.5844\n",
      "Epoch 136/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1313 - accuracy: 0.8752 - val_loss: 1.6104 - val_accuracy: 0.5636\n",
      "Epoch 137/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1315 - accuracy: 0.8776 - val_loss: 1.5853 - val_accuracy: 0.5876\n",
      "Epoch 138/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1305 - accuracy: 0.8737 - val_loss: 1.6158 - val_accuracy: 0.5418\n",
      "Epoch 139/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1306 - accuracy: 0.8738 - val_loss: 1.5715 - val_accuracy: 0.5759\n",
      "Epoch 140/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1279 - accuracy: 0.8840 - val_loss: 1.5400 - val_accuracy: 0.5901\n",
      "Epoch 141/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1280 - accuracy: 0.8809 - val_loss: 1.7293 - val_accuracy: 0.5491\n",
      "Epoch 142/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1304 - accuracy: 0.8760 - val_loss: 2.0137 - val_accuracy: 0.4342\n",
      "Epoch 143/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1399 - accuracy: 0.8704 - val_loss: 1.5604 - val_accuracy: 0.5939\n",
      "Epoch 144/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1269 - accuracy: 0.8783 - val_loss: 2.8797 - val_accuracy: 0.3768\n",
      "Epoch 145/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1494 - accuracy: 0.8618 - val_loss: 1.5444 - val_accuracy: 0.5907\n",
      "Epoch 146/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1267 - accuracy: 0.8861 - val_loss: 1.5723 - val_accuracy: 0.5797\n",
      "Epoch 147/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1255 - accuracy: 0.8836 - val_loss: 1.5497 - val_accuracy: 0.5992\n",
      "Epoch 148/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1242 - accuracy: 0.8831 - val_loss: 1.6159 - val_accuracy: 0.5772\n",
      "Epoch 149/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1232 - accuracy: 0.8872 - val_loss: 1.5549 - val_accuracy: 0.6002\n",
      "Epoch 150/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1226 - accuracy: 0.8853 - val_loss: 1.5834 - val_accuracy: 0.5835\n",
      "Epoch 151/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1234 - accuracy: 0.8879 - val_loss: 1.5744 - val_accuracy: 0.5891\n",
      "Epoch 152/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1223 - accuracy: 0.8864 - val_loss: 1.5834 - val_accuracy: 0.5983\n",
      "Epoch 153/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1218 - accuracy: 0.8865 - val_loss: 1.5992 - val_accuracy: 0.5655\n",
      "Epoch 154/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1225 - accuracy: 0.8855 - val_loss: 1.5710 - val_accuracy: 0.5910\n",
      "Epoch 155/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1212 - accuracy: 0.8894 - val_loss: 1.6198 - val_accuracy: 0.5358\n",
      "Epoch 156/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1218 - accuracy: 0.8897 - val_loss: 1.5771 - val_accuracy: 0.5503\n",
      "Epoch 157/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1237 - accuracy: 0.8873 - val_loss: 1.5971 - val_accuracy: 0.5475\n",
      "Epoch 158/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1230 - accuracy: 0.8856 - val_loss: 1.5730 - val_accuracy: 0.5746\n",
      "Epoch 159/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1202 - accuracy: 0.8879 - val_loss: 1.6102 - val_accuracy: 0.5857\n",
      "Epoch 160/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1204 - accuracy: 0.8899 - val_loss: 1.5819 - val_accuracy: 0.5775\n",
      "Epoch 161/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1193 - accuracy: 0.8921 - val_loss: 1.6114 - val_accuracy: 0.5809\n",
      "Epoch 162/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1186 - accuracy: 0.8921 - val_loss: 1.6564 - val_accuracy: 0.5529\n",
      "Epoch 163/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1198 - accuracy: 0.8932 - val_loss: 1.5531 - val_accuracy: 0.5951\n",
      "Epoch 164/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1171 - accuracy: 0.8962 - val_loss: 1.5879 - val_accuracy: 0.5797\n",
      "Epoch 165/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1173 - accuracy: 0.8925 - val_loss: 1.5703 - val_accuracy: 0.5835\n",
      "Epoch 166/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1162 - accuracy: 0.8942 - val_loss: 1.5769 - val_accuracy: 0.5967\n",
      "Epoch 167/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1166 - accuracy: 0.8956 - val_loss: 1.6694 - val_accuracy: 0.5210\n",
      "Epoch 168/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1202 - accuracy: 0.8870 - val_loss: 1.5673 - val_accuracy: 0.5876\n",
      "Epoch 169/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1158 - accuracy: 0.8953 - val_loss: 1.6503 - val_accuracy: 0.5636\n",
      "Epoch 170/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1166 - accuracy: 0.8937 - val_loss: 1.5699 - val_accuracy: 0.5898\n",
      "Epoch 171/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1161 - accuracy: 0.8996 - val_loss: 1.5964 - val_accuracy: 0.5689\n",
      "Epoch 172/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1165 - accuracy: 0.8927 - val_loss: 1.6297 - val_accuracy: 0.5822\n",
      "Epoch 173/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1164 - accuracy: 0.8958 - val_loss: 1.6424 - val_accuracy: 0.5301\n",
      "Epoch 174/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1199 - accuracy: 0.8896 - val_loss: 1.5743 - val_accuracy: 0.5891\n",
      "Epoch 175/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1158 - accuracy: 0.8943 - val_loss: 1.5770 - val_accuracy: 0.5847\n",
      "Epoch 176/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1146 - accuracy: 0.8963 - val_loss: 1.5607 - val_accuracy: 0.5923\n",
      "Epoch 177/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1151 - accuracy: 0.8935 - val_loss: 1.5926 - val_accuracy: 0.5850\n",
      "Epoch 178/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1139 - accuracy: 0.8972 - val_loss: 1.5816 - val_accuracy: 0.5838\n",
      "Epoch 179/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1134 - accuracy: 0.8982 - val_loss: 1.5600 - val_accuracy: 0.5895\n",
      "Epoch 180/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1128 - accuracy: 0.8995 - val_loss: 1.6079 - val_accuracy: 0.5923\n",
      "Epoch 181/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1134 - accuracy: 0.9019 - val_loss: 1.5886 - val_accuracy: 0.5768\n",
      "Epoch 182/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1133 - accuracy: 0.8997 - val_loss: 1.5594 - val_accuracy: 0.6002\n",
      "Epoch 183/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1125 - accuracy: 0.9021 - val_loss: 1.6672 - val_accuracy: 0.5428\n",
      "Epoch 184/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1145 - accuracy: 0.8998 - val_loss: 1.6624 - val_accuracy: 0.5453\n",
      "Epoch 185/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1140 - accuracy: 0.8959 - val_loss: 1.5924 - val_accuracy: 0.5794\n",
      "Epoch 186/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1131 - accuracy: 0.9010 - val_loss: 1.5636 - val_accuracy: 0.5970\n",
      "Epoch 187/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1119 - accuracy: 0.9008 - val_loss: 1.5715 - val_accuracy: 0.5904\n",
      "Epoch 188/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1128 - accuracy: 0.8981 - val_loss: 1.6312 - val_accuracy: 0.5778\n",
      "Epoch 189/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1114 - accuracy: 0.9012 - val_loss: 1.7960 - val_accuracy: 0.5361\n",
      "Epoch 190/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1135 - accuracy: 0.8991 - val_loss: 1.5918 - val_accuracy: 0.5749\n",
      "Epoch 191/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1116 - accuracy: 0.9023 - val_loss: 1.6647 - val_accuracy: 0.5525\n",
      "Epoch 192/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1145 - accuracy: 0.8944 - val_loss: 1.8765 - val_accuracy: 0.4831\n",
      "Epoch 193/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1134 - accuracy: 0.8989 - val_loss: 1.5885 - val_accuracy: 0.5762\n",
      "Epoch 194/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1106 - accuracy: 0.9029 - val_loss: 1.6478 - val_accuracy: 0.5724\n",
      "Epoch 195/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1102 - accuracy: 0.9033 - val_loss: 1.5673 - val_accuracy: 0.5885\n",
      "Epoch 196/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1094 - accuracy: 0.9037 - val_loss: 1.5568 - val_accuracy: 0.5895\n",
      "Epoch 197/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1094 - accuracy: 0.9070 - val_loss: 1.5618 - val_accuracy: 0.5926\n",
      "Epoch 198/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1096 - accuracy: 0.9043 - val_loss: 1.5817 - val_accuracy: 0.5806\n",
      "Epoch 199/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1091 - accuracy: 0.9054 - val_loss: 1.5860 - val_accuracy: 0.5844\n",
      "Epoch 200/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1099 - accuracy: 0.9037 - val_loss: 1.5670 - val_accuracy: 0.5964\n",
      "Epoch 201/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1088 - accuracy: 0.9059 - val_loss: 1.5555 - val_accuracy: 0.5816\n",
      "Epoch 202/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1080 - accuracy: 0.9088 - val_loss: 1.6615 - val_accuracy: 0.5566\n",
      "Epoch 203/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1107 - accuracy: 0.9015 - val_loss: 1.5854 - val_accuracy: 0.5781\n",
      "Epoch 204/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1094 - accuracy: 0.9059 - val_loss: 1.9524 - val_accuracy: 0.4336\n",
      "Epoch 205/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1218 - accuracy: 0.8870 - val_loss: 1.5528 - val_accuracy: 0.5932\n",
      "Epoch 206/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1091 - accuracy: 0.9048 - val_loss: 1.5951 - val_accuracy: 0.5838\n",
      "Epoch 207/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1074 - accuracy: 0.9086 - val_loss: 1.6126 - val_accuracy: 0.5819\n",
      "Epoch 208/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1090 - accuracy: 0.9017 - val_loss: 1.5589 - val_accuracy: 0.5973\n",
      "Epoch 209/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1067 - accuracy: 0.9082 - val_loss: 1.7424 - val_accuracy: 0.4658\n",
      "Epoch 210/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1169 - accuracy: 0.8922 - val_loss: 1.5788 - val_accuracy: 0.5847\n",
      "Epoch 211/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1089 - accuracy: 0.9089 - val_loss: 1.5650 - val_accuracy: 0.5854\n",
      "Epoch 212/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1075 - accuracy: 0.9080 - val_loss: 2.1723 - val_accuracy: 0.4434\n",
      "Epoch 213/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1151 - accuracy: 0.8962 - val_loss: 1.5929 - val_accuracy: 0.5630\n",
      "Epoch 214/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1087 - accuracy: 0.9074 - val_loss: 1.5665 - val_accuracy: 0.5923\n",
      "Epoch 215/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1067 - accuracy: 0.9078 - val_loss: 1.5653 - val_accuracy: 0.5973\n",
      "Epoch 216/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1058 - accuracy: 0.9100 - val_loss: 1.6550 - val_accuracy: 0.5532\n",
      "Epoch 217/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1064 - accuracy: 0.9090 - val_loss: 1.5783 - val_accuracy: 0.5986\n",
      "Epoch 218/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1048 - accuracy: 0.9096 - val_loss: 1.5741 - val_accuracy: 0.5847\n",
      "Epoch 219/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1049 - accuracy: 0.9120 - val_loss: 1.5709 - val_accuracy: 0.5958\n",
      "Epoch 220/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1063 - accuracy: 0.9110 - val_loss: 1.5670 - val_accuracy: 0.5948\n",
      "Epoch 221/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1063 - accuracy: 0.9054 - val_loss: 1.5742 - val_accuracy: 0.5680\n",
      "Epoch 222/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1053 - accuracy: 0.9093 - val_loss: 1.5645 - val_accuracy: 0.5794\n",
      "Epoch 223/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1041 - accuracy: 0.9127 - val_loss: 1.5682 - val_accuracy: 0.5920\n",
      "Epoch 224/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1041 - accuracy: 0.9115 - val_loss: 1.5581 - val_accuracy: 0.5784\n",
      "Epoch 225/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1039 - accuracy: 0.9123 - val_loss: 1.6570 - val_accuracy: 0.5557\n",
      "Epoch 226/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1059 - accuracy: 0.9117 - val_loss: 1.5715 - val_accuracy: 0.5951\n",
      "Epoch 227/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1043 - accuracy: 0.9101 - val_loss: 1.5870 - val_accuracy: 0.5898\n",
      "Epoch 228/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1037 - accuracy: 0.9142 - val_loss: 1.5580 - val_accuracy: 0.6002\n",
      "Epoch 229/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1038 - accuracy: 0.9127 - val_loss: 1.6029 - val_accuracy: 0.5819\n",
      "Epoch 230/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1034 - accuracy: 0.9137 - val_loss: 1.6087 - val_accuracy: 0.5708\n",
      "Epoch 231/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1038 - accuracy: 0.9123 - val_loss: 1.6067 - val_accuracy: 0.5939\n",
      "Epoch 232/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1041 - accuracy: 0.9125 - val_loss: 1.5645 - val_accuracy: 0.5857\n",
      "Epoch 233/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1039 - accuracy: 0.9079 - val_loss: 1.6705 - val_accuracy: 0.5456\n",
      "Epoch 234/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1052 - accuracy: 0.9097 - val_loss: 1.5698 - val_accuracy: 0.5942\n",
      "Epoch 235/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1036 - accuracy: 0.9140 - val_loss: 1.8170 - val_accuracy: 0.5115\n",
      "Epoch 236/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1064 - accuracy: 0.9068 - val_loss: 1.7411 - val_accuracy: 0.5245\n",
      "Epoch 237/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1073 - accuracy: 0.9039 - val_loss: 1.5631 - val_accuracy: 0.5951\n",
      "Epoch 238/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1036 - accuracy: 0.9142 - val_loss: 1.5635 - val_accuracy: 0.5983\n",
      "Epoch 239/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1023 - accuracy: 0.9157 - val_loss: 1.5634 - val_accuracy: 0.6027\n",
      "Epoch 240/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1028 - accuracy: 0.9157 - val_loss: 1.5926 - val_accuracy: 0.5794\n",
      "Epoch 241/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1031 - accuracy: 0.9131 - val_loss: 1.5577 - val_accuracy: 0.5910\n",
      "Epoch 242/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1031 - accuracy: 0.9120 - val_loss: 1.5606 - val_accuracy: 0.5759\n",
      "Epoch 243/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1022 - accuracy: 0.9162 - val_loss: 1.5675 - val_accuracy: 0.5854\n",
      "Epoch 244/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1021 - accuracy: 0.9135 - val_loss: 1.5636 - val_accuracy: 0.5939\n",
      "Epoch 245/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1017 - accuracy: 0.9174 - val_loss: 1.5676 - val_accuracy: 0.5967\n",
      "Epoch 246/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1019 - accuracy: 0.9146 - val_loss: 1.6403 - val_accuracy: 0.5538\n",
      "Epoch 247/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1024 - accuracy: 0.9148 - val_loss: 1.6647 - val_accuracy: 0.5661\n",
      "Epoch 248/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1030 - accuracy: 0.9144 - val_loss: 1.5754 - val_accuracy: 0.5948\n",
      "Epoch 249/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1014 - accuracy: 0.9166 - val_loss: 1.5626 - val_accuracy: 0.6008\n",
      "Epoch 250/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1009 - accuracy: 0.9210 - val_loss: 1.5700 - val_accuracy: 0.5961\n",
      "Epoch 251/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1018 - accuracy: 0.9114 - val_loss: 1.5684 - val_accuracy: 0.5948\n",
      "Epoch 252/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1016 - accuracy: 0.9173 - val_loss: 1.5644 - val_accuracy: 0.5973\n",
      "Epoch 253/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1011 - accuracy: 0.9157 - val_loss: 1.6171 - val_accuracy: 0.5727\n",
      "Epoch 254/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1014 - accuracy: 0.9153 - val_loss: 1.6051 - val_accuracy: 0.5516\n",
      "Epoch 255/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1039 - accuracy: 0.9130 - val_loss: 1.5620 - val_accuracy: 0.5961\n",
      "Epoch 256/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1018 - accuracy: 0.9147 - val_loss: 1.5553 - val_accuracy: 0.5860\n",
      "Epoch 257/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1034 - accuracy: 0.9120 - val_loss: 1.5719 - val_accuracy: 0.5803\n",
      "Epoch 258/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1016 - accuracy: 0.9139 - val_loss: 1.5987 - val_accuracy: 0.5835\n",
      "Epoch 259/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1014 - accuracy: 0.9161 - val_loss: 1.5796 - val_accuracy: 0.5907\n",
      "Epoch 260/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0999 - accuracy: 0.9182 - val_loss: 1.5661 - val_accuracy: 0.5977\n",
      "Epoch 261/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1001 - accuracy: 0.9211 - val_loss: 1.5672 - val_accuracy: 0.5936\n",
      "Epoch 262/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1005 - accuracy: 0.9197 - val_loss: 1.5701 - val_accuracy: 0.5964\n",
      "Epoch 263/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1001 - accuracy: 0.9179 - val_loss: 1.5554 - val_accuracy: 0.5857\n",
      "Epoch 264/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1001 - accuracy: 0.9169 - val_loss: 1.5913 - val_accuracy: 0.5850\n",
      "Epoch 265/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1002 - accuracy: 0.9182 - val_loss: 1.5626 - val_accuracy: 0.6002\n",
      "Epoch 266/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0997 - accuracy: 0.9209 - val_loss: 1.5663 - val_accuracy: 0.5986\n",
      "Epoch 267/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0992 - accuracy: 0.9200 - val_loss: 1.9364 - val_accuracy: 0.4856\n",
      "Epoch 268/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1063 - accuracy: 0.9104 - val_loss: 1.5715 - val_accuracy: 0.6018\n",
      "Epoch 269/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1001 - accuracy: 0.9169 - val_loss: 1.5774 - val_accuracy: 0.5809\n",
      "Epoch 270/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0998 - accuracy: 0.9212 - val_loss: 1.5706 - val_accuracy: 0.6030\n",
      "Epoch 271/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0993 - accuracy: 0.9213 - val_loss: 1.5607 - val_accuracy: 0.5961\n",
      "Epoch 272/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0991 - accuracy: 0.9200 - val_loss: 1.5690 - val_accuracy: 0.5961\n",
      "Epoch 273/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0981 - accuracy: 0.9227 - val_loss: 1.5503 - val_accuracy: 0.6027\n",
      "Epoch 274/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0990 - accuracy: 0.9223 - val_loss: 1.9082 - val_accuracy: 0.4654\n",
      "Epoch 275/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1017 - accuracy: 0.9121 - val_loss: 1.6135 - val_accuracy: 0.5686\n",
      "Epoch 276/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1005 - accuracy: 0.9184 - val_loss: 1.5933 - val_accuracy: 0.5873\n",
      "Epoch 277/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0996 - accuracy: 0.9168 - val_loss: 1.5689 - val_accuracy: 0.5825\n",
      "Epoch 278/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0990 - accuracy: 0.9204 - val_loss: 1.5674 - val_accuracy: 0.5813\n",
      "Epoch 279/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0992 - accuracy: 0.9209 - val_loss: 1.5623 - val_accuracy: 0.5996\n",
      "Epoch 280/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0980 - accuracy: 0.9230 - val_loss: 1.5540 - val_accuracy: 0.5914\n",
      "Epoch 281/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0985 - accuracy: 0.9215 - val_loss: 1.5549 - val_accuracy: 0.5863\n",
      "Epoch 282/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0989 - accuracy: 0.9215 - val_loss: 1.5550 - val_accuracy: 0.5945\n",
      "Epoch 283/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0987 - accuracy: 0.9181 - val_loss: 1.5725 - val_accuracy: 0.5920\n",
      "Epoch 284/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0982 - accuracy: 0.9234 - val_loss: 1.5882 - val_accuracy: 0.5936\n",
      "Epoch 285/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0982 - accuracy: 0.9223 - val_loss: 1.5752 - val_accuracy: 0.5885\n",
      "Epoch 286/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0990 - accuracy: 0.9218 - val_loss: 1.5528 - val_accuracy: 0.6011\n",
      "Epoch 287/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0976 - accuracy: 0.9246 - val_loss: 1.6002 - val_accuracy: 0.5835\n",
      "Epoch 288/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0982 - accuracy: 0.9213 - val_loss: 1.5584 - val_accuracy: 0.6005\n",
      "Epoch 289/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0977 - accuracy: 0.9212 - val_loss: 1.6284 - val_accuracy: 0.5570\n",
      "Epoch 290/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0987 - accuracy: 0.9190 - val_loss: 4.1441 - val_accuracy: 0.3216\n",
      "Epoch 291/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1271 - accuracy: 0.8881 - val_loss: 1.5877 - val_accuracy: 0.5860\n",
      "Epoch 292/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.1007 - accuracy: 0.9152 - val_loss: 1.5746 - val_accuracy: 0.5961\n",
      "Epoch 293/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0984 - accuracy: 0.9248 - val_loss: 1.6604 - val_accuracy: 0.5573\n",
      "Epoch 294/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0989 - accuracy: 0.9217 - val_loss: 1.5550 - val_accuracy: 0.5986\n",
      "Epoch 295/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0970 - accuracy: 0.9240 - val_loss: 1.8012 - val_accuracy: 0.4970\n",
      "Epoch 296/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.1036 - accuracy: 0.9093 - val_loss: 1.6037 - val_accuracy: 0.5743\n",
      "Epoch 297/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0992 - accuracy: 0.9183 - val_loss: 1.5871 - val_accuracy: 0.5895\n",
      "Epoch 298/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0981 - accuracy: 0.9233 - val_loss: 1.5710 - val_accuracy: 0.6049\n",
      "Epoch 299/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0972 - accuracy: 0.9240 - val_loss: 1.5596 - val_accuracy: 0.5942\n",
      "Epoch 300/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0968 - accuracy: 0.9254 - val_loss: 1.5967 - val_accuracy: 0.5866\n",
      "Epoch 301/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0969 - accuracy: 0.9257 - val_loss: 1.6232 - val_accuracy: 0.5813\n",
      "Epoch 302/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0986 - accuracy: 0.9226 - val_loss: 1.5811 - val_accuracy: 0.5737\n",
      "Epoch 303/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0979 - accuracy: 0.9187 - val_loss: 1.5770 - val_accuracy: 0.5989\n",
      "Epoch 304/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0962 - accuracy: 0.9280 - val_loss: 1.5569 - val_accuracy: 0.5939\n",
      "Epoch 305/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0969 - accuracy: 0.9257 - val_loss: 1.7293 - val_accuracy: 0.5393\n",
      "Epoch 306/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0992 - accuracy: 0.9180 - val_loss: 1.5776 - val_accuracy: 0.5784\n",
      "Epoch 307/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0972 - accuracy: 0.9210 - val_loss: 1.5719 - val_accuracy: 0.5999\n",
      "Epoch 308/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0964 - accuracy: 0.9268 - val_loss: 1.5660 - val_accuracy: 0.5955\n",
      "Epoch 309/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0962 - accuracy: 0.9280 - val_loss: 1.5718 - val_accuracy: 0.6052\n",
      "Epoch 310/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0956 - accuracy: 0.9274 - val_loss: 1.5650 - val_accuracy: 0.6008\n",
      "Epoch 311/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0959 - accuracy: 0.9286 - val_loss: 1.5725 - val_accuracy: 0.5955\n",
      "Epoch 312/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0961 - accuracy: 0.9255 - val_loss: 1.5602 - val_accuracy: 0.6043\n",
      "Epoch 313/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0958 - accuracy: 0.9261 - val_loss: 1.5549 - val_accuracy: 0.5989\n",
      "Epoch 314/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0959 - accuracy: 0.9266 - val_loss: 1.5760 - val_accuracy: 0.5910\n",
      "Epoch 315/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0957 - accuracy: 0.9288 - val_loss: 1.5713 - val_accuracy: 0.5860\n",
      "Epoch 316/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0958 - accuracy: 0.9260 - val_loss: 1.5691 - val_accuracy: 0.5983\n",
      "Epoch 317/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0956 - accuracy: 0.9246 - val_loss: 1.5696 - val_accuracy: 0.5948\n",
      "Epoch 318/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0956 - accuracy: 0.9288 - val_loss: 1.5744 - val_accuracy: 0.5973\n",
      "Epoch 319/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0959 - accuracy: 0.9233 - val_loss: 1.5961 - val_accuracy: 0.5797\n",
      "Epoch 320/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0962 - accuracy: 0.9281 - val_loss: 1.7510 - val_accuracy: 0.5030\n",
      "Epoch 321/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0987 - accuracy: 0.9188 - val_loss: 1.5718 - val_accuracy: 0.5992\n",
      "Epoch 322/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0967 - accuracy: 0.9243 - val_loss: 1.5841 - val_accuracy: 0.5942\n",
      "Epoch 323/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0967 - accuracy: 0.9223 - val_loss: 1.5650 - val_accuracy: 0.5910\n",
      "Epoch 324/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0956 - accuracy: 0.9251 - val_loss: 1.5701 - val_accuracy: 0.5955\n",
      "Epoch 325/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0951 - accuracy: 0.9297 - val_loss: 1.5493 - val_accuracy: 0.5967\n",
      "Epoch 326/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0947 - accuracy: 0.9288 - val_loss: 1.5575 - val_accuracy: 0.5958\n",
      "Epoch 327/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0946 - accuracy: 0.9291 - val_loss: 1.5704 - val_accuracy: 0.5885\n",
      "Epoch 328/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0946 - accuracy: 0.9290 - val_loss: 1.5614 - val_accuracy: 0.5920\n",
      "Epoch 329/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0943 - accuracy: 0.9304 - val_loss: 1.5641 - val_accuracy: 0.5926\n",
      "Epoch 330/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0943 - accuracy: 0.9306 - val_loss: 1.5689 - val_accuracy: 0.5891\n",
      "Epoch 331/500\n",
      "397/397 [==============================] - 22s 57ms/step - loss: 1.0946 - accuracy: 0.9303 - val_loss: 1.5557 - val_accuracy: 0.5961\n",
      "Epoch 332/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0942 - accuracy: 0.9303 - val_loss: 1.5843 - val_accuracy: 0.5854\n",
      "Epoch 333/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0947 - accuracy: 0.9307 - val_loss: 1.5714 - val_accuracy: 0.6018\n",
      "Epoch 334/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0946 - accuracy: 0.9275 - val_loss: 1.5734 - val_accuracy: 0.6002\n",
      "Epoch 335/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0953 - accuracy: 0.9271 - val_loss: 1.5799 - val_accuracy: 0.5879\n",
      "Epoch 336/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0956 - accuracy: 0.9231 - val_loss: 1.5694 - val_accuracy: 0.5977\n",
      "Epoch 337/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0945 - accuracy: 0.9317 - val_loss: 1.5789 - val_accuracy: 0.5891\n",
      "Epoch 338/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0943 - accuracy: 0.9273 - val_loss: 1.5813 - val_accuracy: 0.5904\n",
      "Epoch 339/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0949 - accuracy: 0.9256 - val_loss: 1.5801 - val_accuracy: 0.5948\n",
      "Epoch 340/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0942 - accuracy: 0.9295 - val_loss: 1.5647 - val_accuracy: 0.5980\n",
      "Epoch 341/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0946 - accuracy: 0.9286 - val_loss: 1.5727 - val_accuracy: 0.6018\n",
      "Epoch 342/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0948 - accuracy: 0.9312 - val_loss: 1.5582 - val_accuracy: 0.5955\n",
      "Epoch 343/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0949 - accuracy: 0.9290 - val_loss: 1.6388 - val_accuracy: 0.5595\n",
      "Epoch 344/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0961 - accuracy: 0.9233 - val_loss: 1.6854 - val_accuracy: 0.5563\n",
      "Epoch 345/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0961 - accuracy: 0.9261 - val_loss: 1.5712 - val_accuracy: 0.5828\n",
      "Epoch 346/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0953 - accuracy: 0.9283 - val_loss: 1.5645 - val_accuracy: 0.5996\n",
      "Epoch 347/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0940 - accuracy: 0.9282 - val_loss: 1.5791 - val_accuracy: 0.5860\n",
      "Epoch 348/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0940 - accuracy: 0.9291 - val_loss: 1.6780 - val_accuracy: 0.5541\n",
      "Epoch 349/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0967 - accuracy: 0.9241 - val_loss: 1.5859 - val_accuracy: 0.5904\n",
      "Epoch 350/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0952 - accuracy: 0.9263 - val_loss: 1.5647 - val_accuracy: 0.5980\n",
      "Epoch 351/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0942 - accuracy: 0.9299 - val_loss: 1.5841 - val_accuracy: 0.5819\n",
      "Epoch 352/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0941 - accuracy: 0.9289 - val_loss: 1.5650 - val_accuracy: 0.6043\n",
      "Epoch 353/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0934 - accuracy: 0.9355 - val_loss: 1.5645 - val_accuracy: 0.5939\n",
      "Epoch 354/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0932 - accuracy: 0.9302 - val_loss: 1.5583 - val_accuracy: 0.5980\n",
      "Epoch 355/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0930 - accuracy: 0.9300 - val_loss: 1.5665 - val_accuracy: 0.5989\n",
      "Epoch 356/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0933 - accuracy: 0.9339 - val_loss: 1.5693 - val_accuracy: 0.5939\n",
      "Epoch 357/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0933 - accuracy: 0.9302 - val_loss: 1.5667 - val_accuracy: 0.5948\n",
      "Epoch 358/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0935 - accuracy: 0.9325 - val_loss: 1.5620 - val_accuracy: 0.6081\n",
      "Epoch 359/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0933 - accuracy: 0.9357 - val_loss: 1.6408 - val_accuracy: 0.5620\n",
      "Epoch 360/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0946 - accuracy: 0.9269 - val_loss: 1.5660 - val_accuracy: 0.5977\n",
      "Epoch 361/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0933 - accuracy: 0.9333 - val_loss: 1.5649 - val_accuracy: 0.5996\n",
      "Epoch 362/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0934 - accuracy: 0.9282 - val_loss: 1.5638 - val_accuracy: 0.5917\n",
      "Epoch 363/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0932 - accuracy: 0.9284 - val_loss: 1.5871 - val_accuracy: 0.5876\n",
      "Epoch 364/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0938 - accuracy: 0.9321 - val_loss: 1.6584 - val_accuracy: 0.5519\n",
      "Epoch 365/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0955 - accuracy: 0.9257 - val_loss: 1.5839 - val_accuracy: 0.5854\n",
      "Epoch 366/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0944 - accuracy: 0.9267 - val_loss: 1.7089 - val_accuracy: 0.5459\n",
      "Epoch 367/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0958 - accuracy: 0.9237 - val_loss: 1.5652 - val_accuracy: 0.5973\n",
      "Epoch 368/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0935 - accuracy: 0.9285 - val_loss: 1.5634 - val_accuracy: 0.5958\n",
      "Epoch 369/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0930 - accuracy: 0.9336 - val_loss: 1.5658 - val_accuracy: 0.5951\n",
      "Epoch 370/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0930 - accuracy: 0.9349 - val_loss: 1.6191 - val_accuracy: 0.5759\n",
      "Epoch 371/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0958 - accuracy: 0.9254 - val_loss: 1.5811 - val_accuracy: 0.5756\n",
      "Epoch 372/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0957 - accuracy: 0.9232 - val_loss: 1.5646 - val_accuracy: 0.5989\n",
      "Epoch 373/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0941 - accuracy: 0.9303 - val_loss: 1.5670 - val_accuracy: 0.5961\n",
      "Epoch 374/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0929 - accuracy: 0.9318 - val_loss: 1.5829 - val_accuracy: 0.5712\n",
      "Epoch 375/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0933 - accuracy: 0.9325 - val_loss: 1.5677 - val_accuracy: 0.5973\n",
      "Epoch 376/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0922 - accuracy: 0.9362 - val_loss: 1.5628 - val_accuracy: 0.5961\n",
      "Epoch 377/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0917 - accuracy: 0.9370 - val_loss: 1.5662 - val_accuracy: 0.6011\n",
      "Epoch 378/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0918 - accuracy: 0.9373 - val_loss: 1.5882 - val_accuracy: 0.6011\n",
      "Epoch 379/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0926 - accuracy: 0.9336 - val_loss: 1.5915 - val_accuracy: 0.6015\n",
      "Epoch 380/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0926 - accuracy: 0.9323 - val_loss: 1.6088 - val_accuracy: 0.5775\n",
      "Epoch 381/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0929 - accuracy: 0.9303 - val_loss: 1.5656 - val_accuracy: 0.5895\n",
      "Epoch 382/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0932 - accuracy: 0.9288 - val_loss: 1.5713 - val_accuracy: 0.6002\n",
      "Epoch 383/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0923 - accuracy: 0.9346 - val_loss: 1.5657 - val_accuracy: 0.5961\n",
      "Epoch 384/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0920 - accuracy: 0.9314 - val_loss: 1.7097 - val_accuracy: 0.5131\n",
      "Epoch 385/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0959 - accuracy: 0.9254 - val_loss: 1.5611 - val_accuracy: 0.5879\n",
      "Epoch 386/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0933 - accuracy: 0.9300 - val_loss: 1.5666 - val_accuracy: 0.5929\n",
      "Epoch 387/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0925 - accuracy: 0.9333 - val_loss: 1.5826 - val_accuracy: 0.5970\n",
      "Epoch 388/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0922 - accuracy: 0.9329 - val_loss: 1.5686 - val_accuracy: 0.5992\n",
      "Epoch 389/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0920 - accuracy: 0.9360 - val_loss: 1.5762 - val_accuracy: 0.5914\n",
      "Epoch 390/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0916 - accuracy: 0.9341 - val_loss: 1.5667 - val_accuracy: 0.6008\n",
      "Epoch 391/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0915 - accuracy: 0.9377 - val_loss: 1.5698 - val_accuracy: 0.5989\n",
      "Epoch 392/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0913 - accuracy: 0.9382 - val_loss: 1.5787 - val_accuracy: 0.5844\n",
      "Epoch 393/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0919 - accuracy: 0.9364 - val_loss: 1.5859 - val_accuracy: 0.5936\n",
      "Epoch 394/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0918 - accuracy: 0.9339 - val_loss: 1.5762 - val_accuracy: 0.5939\n",
      "Epoch 395/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0917 - accuracy: 0.9357 - val_loss: 1.5687 - val_accuracy: 0.6002\n",
      "Epoch 396/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0919 - accuracy: 0.9359 - val_loss: 1.5700 - val_accuracy: 0.5986\n",
      "Epoch 397/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0914 - accuracy: 0.9362 - val_loss: 1.5872 - val_accuracy: 0.5869\n",
      "Epoch 398/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0916 - accuracy: 0.9344 - val_loss: 1.5758 - val_accuracy: 0.5961\n",
      "Epoch 399/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0917 - accuracy: 0.9350 - val_loss: 1.6191 - val_accuracy: 0.5686\n",
      "Epoch 400/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0935 - accuracy: 0.9310 - val_loss: 1.5667 - val_accuracy: 0.5996\n",
      "Epoch 401/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0923 - accuracy: 0.9312 - val_loss: 1.5665 - val_accuracy: 0.5907\n",
      "Epoch 402/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0925 - accuracy: 0.9345 - val_loss: 1.6262 - val_accuracy: 0.5538\n",
      "Epoch 403/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0939 - accuracy: 0.9269 - val_loss: 1.5777 - val_accuracy: 0.6005\n",
      "Epoch 404/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0926 - accuracy: 0.9293 - val_loss: 1.5656 - val_accuracy: 0.5999\n",
      "Epoch 405/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0920 - accuracy: 0.9357 - val_loss: 1.5707 - val_accuracy: 0.6011\n",
      "Epoch 406/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0918 - accuracy: 0.9325 - val_loss: 1.5864 - val_accuracy: 0.5822\n",
      "Epoch 407/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0928 - accuracy: 0.9324 - val_loss: 1.5630 - val_accuracy: 0.5939\n",
      "Epoch 408/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0920 - accuracy: 0.9326 - val_loss: 1.5748 - val_accuracy: 0.5866\n",
      "Epoch 409/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0924 - accuracy: 0.9322 - val_loss: 1.5641 - val_accuracy: 0.5999\n",
      "Epoch 410/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0917 - accuracy: 0.9339 - val_loss: 1.5741 - val_accuracy: 0.5986\n",
      "Epoch 411/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0916 - accuracy: 0.9358 - val_loss: 1.5954 - val_accuracy: 0.5838\n",
      "Epoch 412/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0915 - accuracy: 0.9357 - val_loss: 1.5654 - val_accuracy: 0.5942\n",
      "Epoch 413/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0911 - accuracy: 0.9405 - val_loss: 1.5673 - val_accuracy: 0.6002\n",
      "Epoch 414/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0910 - accuracy: 0.9359 - val_loss: 1.5990 - val_accuracy: 0.5762\n",
      "Epoch 415/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0921 - accuracy: 0.9346 - val_loss: 1.7839 - val_accuracy: 0.5267\n",
      "Epoch 416/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0968 - accuracy: 0.9243 - val_loss: 1.5699 - val_accuracy: 0.5977\n",
      "Epoch 417/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0928 - accuracy: 0.9316 - val_loss: 1.5588 - val_accuracy: 0.5914\n",
      "Epoch 418/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0916 - accuracy: 0.9329 - val_loss: 1.5690 - val_accuracy: 0.5948\n",
      "Epoch 419/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0911 - accuracy: 0.9368 - val_loss: 1.5934 - val_accuracy: 0.5857\n",
      "Epoch 420/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0912 - accuracy: 0.9353 - val_loss: 1.5619 - val_accuracy: 0.5989\n",
      "Epoch 421/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0914 - accuracy: 0.9349 - val_loss: 1.5742 - val_accuracy: 0.5850\n",
      "Epoch 422/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0921 - accuracy: 0.9314 - val_loss: 1.5975 - val_accuracy: 0.5866\n",
      "Epoch 423/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0933 - accuracy: 0.9294 - val_loss: 1.5643 - val_accuracy: 0.5863\n",
      "Epoch 424/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0918 - accuracy: 0.9370 - val_loss: 1.5941 - val_accuracy: 0.5876\n",
      "Epoch 425/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0920 - accuracy: 0.9316 - val_loss: 1.5799 - val_accuracy: 0.5904\n",
      "Epoch 426/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0915 - accuracy: 0.9380 - val_loss: 1.5573 - val_accuracy: 0.5888\n",
      "Epoch 427/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0921 - accuracy: 0.9338 - val_loss: 1.5681 - val_accuracy: 0.5980\n",
      "Epoch 428/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0913 - accuracy: 0.9321 - val_loss: 1.6061 - val_accuracy: 0.5718\n",
      "Epoch 429/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0915 - accuracy: 0.9351 - val_loss: 1.5722 - val_accuracy: 0.5904\n",
      "Epoch 430/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0910 - accuracy: 0.9376 - val_loss: 1.5728 - val_accuracy: 0.5844\n",
      "Epoch 431/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0909 - accuracy: 0.9322 - val_loss: 1.5684 - val_accuracy: 0.6002\n",
      "Epoch 432/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0908 - accuracy: 0.9375 - val_loss: 1.5627 - val_accuracy: 0.5929\n",
      "Epoch 433/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0908 - accuracy: 0.9396 - val_loss: 1.5772 - val_accuracy: 0.5951\n",
      "Epoch 434/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0908 - accuracy: 0.9381 - val_loss: 1.5654 - val_accuracy: 0.5955\n",
      "Epoch 435/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0905 - accuracy: 0.9384 - val_loss: 1.6167 - val_accuracy: 0.5658\n",
      "Epoch 436/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0922 - accuracy: 0.9327 - val_loss: 1.5718 - val_accuracy: 0.5926\n",
      "Epoch 437/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0905 - accuracy: 0.9379 - val_loss: 1.5848 - val_accuracy: 0.5794\n",
      "Epoch 438/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0909 - accuracy: 0.9381 - val_loss: 1.5718 - val_accuracy: 0.6008\n",
      "Epoch 439/500\n",
      "397/397 [==============================] - 23s 57ms/step - loss: 1.0908 - accuracy: 0.9354 - val_loss: 1.5747 - val_accuracy: 0.5885\n",
      "Epoch 440/500\n",
      "397/397 [==============================] - 23s 57ms/step - loss: 1.0904 - accuracy: 0.9362 - val_loss: 1.5764 - val_accuracy: 0.5942\n",
      "Epoch 441/500\n",
      "397/397 [==============================] - 21s 54ms/step - loss: 1.0901 - accuracy: 0.9401 - val_loss: 1.5729 - val_accuracy: 0.5986\n",
      "Epoch 442/500\n",
      "397/397 [==============================] - 21s 54ms/step - loss: 1.0904 - accuracy: 0.9394 - val_loss: 1.5945 - val_accuracy: 0.5737\n",
      "Epoch 443/500\n",
      "397/397 [==============================] - 21s 54ms/step - loss: 1.0910 - accuracy: 0.9364 - val_loss: 1.5669 - val_accuracy: 0.5939\n",
      "Epoch 444/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0904 - accuracy: 0.9390 - val_loss: 1.5708 - val_accuracy: 0.5958\n",
      "Epoch 445/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0903 - accuracy: 0.9408 - val_loss: 1.6038 - val_accuracy: 0.5835\n",
      "Epoch 446/500\n",
      "397/397 [==============================] - 21s 54ms/step - loss: 1.0913 - accuracy: 0.9334 - val_loss: 1.5790 - val_accuracy: 0.5932\n",
      "Epoch 447/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0915 - accuracy: 0.9321 - val_loss: 1.5685 - val_accuracy: 0.5992\n",
      "Epoch 448/500\n",
      "397/397 [==============================] - 22s 57ms/step - loss: 1.0909 - accuracy: 0.9400 - val_loss: 1.5778 - val_accuracy: 0.5948\n",
      "Epoch 449/500\n",
      "397/397 [==============================] - 24s 60ms/step - loss: 1.0903 - accuracy: 0.9396 - val_loss: 1.5631 - val_accuracy: 0.5983\n",
      "Epoch 450/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0900 - accuracy: 0.9422 - val_loss: 1.7553 - val_accuracy: 0.5222\n",
      "Epoch 451/500\n",
      "397/397 [==============================] - 23s 57ms/step - loss: 1.0954 - accuracy: 0.9221 - val_loss: 1.5920 - val_accuracy: 0.6002\n",
      "Epoch 452/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0921 - accuracy: 0.9286 - val_loss: 1.6205 - val_accuracy: 0.5680\n",
      "Epoch 453/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0921 - accuracy: 0.9316 - val_loss: 1.5681 - val_accuracy: 0.5945\n",
      "Epoch 454/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0912 - accuracy: 0.9355 - val_loss: 1.5812 - val_accuracy: 0.5876\n",
      "Epoch 455/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0920 - accuracy: 0.9310 - val_loss: 1.5676 - val_accuracy: 0.6002\n",
      "Epoch 456/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0907 - accuracy: 0.9359 - val_loss: 1.5678 - val_accuracy: 0.5961\n",
      "Epoch 457/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0900 - accuracy: 0.9396 - val_loss: 1.5705 - val_accuracy: 0.5951\n",
      "Epoch 458/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0902 - accuracy: 0.9385 - val_loss: 1.5685 - val_accuracy: 0.5958\n",
      "Epoch 459/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0900 - accuracy: 0.9372 - val_loss: 1.5728 - val_accuracy: 0.6024\n",
      "Epoch 460/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0897 - accuracy: 0.9422 - val_loss: 1.5708 - val_accuracy: 0.6021\n",
      "Epoch 461/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0894 - accuracy: 0.9430 - val_loss: 1.5815 - val_accuracy: 0.5923\n",
      "Epoch 462/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0894 - accuracy: 0.9413 - val_loss: 1.5708 - val_accuracy: 0.5951\n",
      "Epoch 463/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0890 - accuracy: 0.9408 - val_loss: 1.5747 - val_accuracy: 0.5961\n",
      "Epoch 464/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0895 - accuracy: 0.9436 - val_loss: 1.5699 - val_accuracy: 0.5989\n",
      "Epoch 465/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0894 - accuracy: 0.9413 - val_loss: 1.5939 - val_accuracy: 0.5790\n",
      "Epoch 466/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0903 - accuracy: 0.9404 - val_loss: 1.5865 - val_accuracy: 0.5888\n",
      "Epoch 467/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0903 - accuracy: 0.9374 - val_loss: 1.5681 - val_accuracy: 0.5939\n",
      "Epoch 468/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0904 - accuracy: 0.9365 - val_loss: 1.5728 - val_accuracy: 0.5992\n",
      "Epoch 469/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0901 - accuracy: 0.9409 - val_loss: 1.5752 - val_accuracy: 0.5898\n",
      "Epoch 470/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0905 - accuracy: 0.9359 - val_loss: 1.5698 - val_accuracy: 0.6015\n",
      "Epoch 471/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0904 - accuracy: 0.9369 - val_loss: 1.5664 - val_accuracy: 0.5977\n",
      "Epoch 472/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0901 - accuracy: 0.9393 - val_loss: 1.5647 - val_accuracy: 0.5958\n",
      "Epoch 473/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0897 - accuracy: 0.9406 - val_loss: 1.5737 - val_accuracy: 0.5964\n",
      "Epoch 474/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0899 - accuracy: 0.9391 - val_loss: 1.5679 - val_accuracy: 0.5980\n",
      "Epoch 475/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0899 - accuracy: 0.9387 - val_loss: 1.5706 - val_accuracy: 0.5920\n",
      "Epoch 476/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0900 - accuracy: 0.9405 - val_loss: 1.5712 - val_accuracy: 0.5977\n",
      "Epoch 477/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0898 - accuracy: 0.9403 - val_loss: 1.5843 - val_accuracy: 0.5901\n",
      "Epoch 478/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0895 - accuracy: 0.9388 - val_loss: 1.5715 - val_accuracy: 0.5910\n",
      "Epoch 479/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0895 - accuracy: 0.9390 - val_loss: 1.5657 - val_accuracy: 0.5917\n",
      "Epoch 480/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0896 - accuracy: 0.9444 - val_loss: 1.5866 - val_accuracy: 0.5816\n",
      "Epoch 481/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0903 - accuracy: 0.9348 - val_loss: 1.5782 - val_accuracy: 0.5939\n",
      "Epoch 482/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0907 - accuracy: 0.9346 - val_loss: 1.5722 - val_accuracy: 0.5920\n",
      "Epoch 483/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0904 - accuracy: 0.9379 - val_loss: 1.5662 - val_accuracy: 0.5973\n",
      "Epoch 484/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0902 - accuracy: 0.9404 - val_loss: 1.5662 - val_accuracy: 0.5948\n",
      "Epoch 485/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0897 - accuracy: 0.9411 - val_loss: 1.6762 - val_accuracy: 0.5689\n",
      "Epoch 486/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0926 - accuracy: 0.9315 - val_loss: 1.5639 - val_accuracy: 0.5992\n",
      "Epoch 487/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0906 - accuracy: 0.9353 - val_loss: 1.5633 - val_accuracy: 0.6008\n",
      "Epoch 488/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0901 - accuracy: 0.9378 - val_loss: 1.5726 - val_accuracy: 0.5951\n",
      "Epoch 489/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0896 - accuracy: 0.9404 - val_loss: 1.5584 - val_accuracy: 0.5942\n",
      "Epoch 490/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0894 - accuracy: 0.9393 - val_loss: 1.5796 - val_accuracy: 0.5926\n",
      "Epoch 491/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0892 - accuracy: 0.9433 - val_loss: 1.5738 - val_accuracy: 0.5948\n",
      "Epoch 492/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0890 - accuracy: 0.9403 - val_loss: 1.5700 - val_accuracy: 0.5964\n",
      "Epoch 493/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0892 - accuracy: 0.9418 - val_loss: 1.5621 - val_accuracy: 0.5920\n",
      "Epoch 494/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0894 - accuracy: 0.9418 - val_loss: 1.6286 - val_accuracy: 0.5405\n",
      "Epoch 495/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0921 - accuracy: 0.9321 - val_loss: 1.5750 - val_accuracy: 0.5948\n",
      "Epoch 496/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0904 - accuracy: 0.9358 - val_loss: 1.5886 - val_accuracy: 0.6062\n",
      "Epoch 497/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0902 - accuracy: 0.9348 - val_loss: 1.5744 - val_accuracy: 0.5869\n",
      "Epoch 498/500\n",
      "397/397 [==============================] - 22s 56ms/step - loss: 1.0906 - accuracy: 0.9346 - val_loss: 1.5599 - val_accuracy: 0.5854\n",
      "Epoch 499/500\n",
      "397/397 [==============================] - 23s 57ms/step - loss: 1.0900 - accuracy: 0.9364 - val_loss: 1.5696 - val_accuracy: 0.5860\n",
      "Epoch 500/500\n",
      "397/397 [==============================] - 22s 55ms/step - loss: 1.0899 - accuracy: 0.9393 - val_loss: 1.5740 - val_accuracy: 0.5819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2613166efa0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xs, ys, epochs=500, validation_data=(xs_test, ys_test), batch_size=32, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test loss on both test and train data\n",
    "loss_test = model.evaluate(xs_test, ys_test)\n",
    "loss_train = model.evaluate(xs, ys)\n",
    "print(f\"Test loss: {loss_test}\")\n",
    "print(f\"Train loss: {loss_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the starting position, we expect this dist\n",
    "plt.bar(range(7), firstpolicy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_board = np.zeros((6, 7, 2)) # looks like the starting position\n",
    "dist = model.predict(mock_board.reshape(1, 6, 7, 2))[0]\n",
    "# plot dist as a bar chart\n",
    "plt.bar(range(7), dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_board[5, 3, 0] = 1  # place a piece in column 4 (index 3)\n",
    "dist = model.predict(mock_board.reshape(1, 6, 7, 2))[0]\n",
    "# plot dist as a bar chart\n",
    "plt.bar(range(7), dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_board[4, 3, 1] = 1  # place a piece in column 4 (index 3)\n",
    "mock_board[5, 2, 0] = 1  # place a piece in column 3 (index 2)\n",
    "dist = model.predict(mock_board.reshape(1, 6, 7, 2))[0]\n",
    "# plot dist as a bar chart\n",
    "plt.bar(range(7), dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model.save('direct_conv_policy.h5')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b52cd1b9a8a0035b2cd3385048b7442b6ba2d26e4ca84d1db37ccdeb82b891dc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
